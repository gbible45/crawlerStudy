## 03. 유튜브 크롤러
- package import
```python
#-*- coding: utf-8 -*-

# set options to be headless, ..
try:
    from selenium import webdriver
except:
    !pip install selenium
    from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

try:
    from webdriver_manager.chrome import ChromeDriverManager
except:
    !pip install webdriver_manager
    from webdriver_manager.chrome import ChromeDriverManager

try:
    from urllib.parse import urlencode
except:
    !pip install urllib3
    from urllib.parse import urlencode
import datetime
import time

try:
    import csv
except:
    !pip install csv
    import csv

```
- 브라우저 옵션
```python
# 브라우저 옵션
options = webdriver.ChromeOptions()
# options.add_argument('headless')
options.add_argument('start-maximized')
options.add_argument(
            "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36"
        )
options.add_argument("lang=ko_KR")
```
- elements 쿼리 설정 
```python
# 루프 제한 값
sleepMaxCount = 5
# select query
item_query = "ytd-video-renderer.style-scope.ytd-item-section-renderer"
title_query = "div#title-wrapper yt-formatted-string.style-scope.ytd-video-renderer"
contents_query = "yt-formatted-string[id=description-text]"
like_query = "ytd-video-meta-block.style-scope.ytd-video-renderer.byline-separated > div#metadata > div#metadata-line > span"
time_query = "ytd-video-meta-block.style-scope.ytd-video-renderer.byline-separated > div#metadata > div#metadata-line > span"
channel_query = "ytd-channel-name#channel-name.long-byline,style-scope,ytd-video-renderer > div#container > div#text-container > yt-formatted-string.style-scope.ytd-channel-name > a"

```
- 데이터 추출 함수
```python
# 데이터 추출 함수
def startSearch() :
    encode_type = "utf-8"

    if __name__ == '__main__' or 'google.colab' in sys.modules:
        chrome = webdriver.Chrome('chromedriver', options=options)
        try:
            search_txt = input("search : ")
            sq={"search_query":search_txt}
            search_encode = urlencode(sq)
            chrome.get("https://www.youtube.com/results?" + search_encode + "&sp=CAISAggF")

            i=0
            dataRuw=0
            isEnd=0
            time.sleep(1)

            # 초기 파일 생성
            now_date = datetime.datetime.now()
            cvsFileName = "youtube_search_" + search_txt + "_" + now_date.strftime("%Y-%m-%d") + ".csv"
            with open(cvsFileName, "w", newline="", encoding=encode_type) as f:
                colnames = ['number', 'title', 'contents', 'like', 'time', "channel"]
                w = csv.writer(f)
                w.writerow(colnames)

            # 데이터 추출을 위한 루프
            while True:
                isEnd = 0
                items = chrome.find_elements(By.CSS_SELECTOR, item_query)
                item_len = len(items)

                # 데이터 로드 될때까지 루프, 최대 sleepMaxCount 까지만 루프
                while item_len <= dataRuw and isEnd < sleepMaxCount:
                    time.sleep(1)
                    items = chrome.find_elements(By.CSS_SELECTOR, item_query)
                    item_len = len(items)
                    isEnd = isEnd + 1

                # 최대 sleepMaxCount 루프까지 진행 된게 아이라면 isEnd 초기화
                if item_len <= dataRuw:
                    break
                else :
                    isEnd = 0
                    
                with open(cvsFileName, "a", newline="", encoding=encode_type) as f:
                    w = csv.writer(f)
                    number = 0
                    for item in items[dataRuw:]:
                        number=number+1
                        title_txt = ""
                        contents_txt = ""
                        like_txt = ""
                        time_txt = ""
                        channel_txt = ""

                        try:
                            title_txt = item.find_element(By.CSS_SELECTOR, title_query).text
                        except Exception as e:
                            #print(e)
                            title_txt = ""

                        try:
                            contents_txt = item.find_element(By.CSS_SELECTOR, contents_query).text
                        except Exception as e:
                            #print(e)
                            contents_txt = ""

                        try:
                            like_txt = item.find_elements(By.CSS_SELECTOR, like_query)[0].text
                        except Exception as e:
                            #print(e)
                            like_txt = ""

                        try:
                            time_txt = item.find_elements(By.CSS_SELECTOR, time_query)[1].text
                        except Exception as e:
                            #print(e)
                            time_txt = ""

                        try:
                            channel_txt = item.find_element(By.CSS_SELECTOR, channel_query).text
                        except Exception as e:
                            #print(e)
                            channel_txt = ""

                        data = [number, title_txt, contents_txt, like_txt, time_txt, channel_txt]
                        print(data)
                        w.writerow(data)

                dataRuw = item_len

                i = i+1
                print("스크롤 : ", i)
                print("데이터 건수 : ", dataRuw)

                # 브라우저 스크롤 맨 아래로 이동
                chrome.execute_script("window.scrollTo(0, document.getElementById('content').scrollHeight);")
                time.sleep(1)
        except Exception as e:
            print(e)
        finally:
            if chrome:
                chrome.close()

```
- 데이터 추출 시작
```python
startSearch()
```
